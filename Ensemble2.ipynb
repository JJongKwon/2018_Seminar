{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ensemble.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"mz2cqCGVzezq","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sTz6A5_yAO3o","colab_type":"text"},"cell_type":"markdown","source":["데이터에 대한 설명과 전처리는 [여기]()"]},{"metadata":{"id":"mnC06wLzzezv","colab_type":"code","colab":{}},"cell_type":"code","source":["features = pd.read_csv(\"https://raw.githubusercontent.com/JJongKwon/Seminar/master/features.csv\")\n","target = pd.read_csv(\"https://raw.githubusercontent.com/JJongKwon/Seminar/master/target.csv\", header=None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CvoldLxOzezy","colab_type":"code","outputId":"f7692f87-0341-4985-d987-0f268fdb7cf3","executionInfo":{"status":"ok","timestamp":1542446966704,"user_tz":-540,"elapsed":639,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"cell_type":"code","source":["features.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HE_ht</th>\n","      <th>HE_wt</th>\n","      <th>HE_wc</th>\n","      <th>HE_BMI</th>\n","      <th>N_WAT_C</th>\n","      <th>N_INTK</th>\n","      <th>N_EN</th>\n","      <th>N_WATER</th>\n","      <th>N_PROT</th>\n","      <th>N_FAT</th>\n","      <th>...</th>\n","      <th>HE_HP_2.0</th>\n","      <th>HE_HP_3.0</th>\n","      <th>HE_DM_1.0</th>\n","      <th>HE_DM_2.0</th>\n","      <th>HE_DM_3.0</th>\n","      <th>HE_HCHOL_0.0</th>\n","      <th>HE_HCHOL_1.0</th>\n","      <th>GS_use_1.0</th>\n","      <th>GS_use_2.0</th>\n","      <th>GS_use_3.0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>153.4</td>\n","      <td>68.1</td>\n","      <td>81.9</td>\n","      <td>28.939858</td>\n","      <td>3.5</td>\n","      <td>1198.226616</td>\n","      <td>1930.920992</td>\n","      <td>761.873294</td>\n","      <td>69.515824</td>\n","      <td>57.722349</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>171.2</td>\n","      <td>84.0</td>\n","      <td>85.5</td>\n","      <td>28.659708</td>\n","      <td>4.0</td>\n","      <td>2099.617699</td>\n","      <td>3007.329713</td>\n","      <td>1427.204406</td>\n","      <td>109.849807</td>\n","      <td>100.764835</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>160.8</td>\n","      <td>52.2</td>\n","      <td>71.0</td>\n","      <td>20.188238</td>\n","      <td>3.0</td>\n","      <td>779.230888</td>\n","      <td>1502.406756</td>\n","      <td>443.763134</td>\n","      <td>57.129583</td>\n","      <td>39.501421</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>168.8</td>\n","      <td>68.8</td>\n","      <td>84.0</td>\n","      <td>24.145909</td>\n","      <td>5.0</td>\n","      <td>1165.590400</td>\n","      <td>1116.380721</td>\n","      <td>911.584789</td>\n","      <td>36.183575</td>\n","      <td>28.630711</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>162.2</td>\n","      <td>80.5</td>\n","      <td>98.4</td>\n","      <td>30.598080</td>\n","      <td>15.0</td>\n","      <td>2336.472416</td>\n","      <td>2465.075672</td>\n","      <td>1897.949605</td>\n","      <td>72.131360</td>\n","      <td>68.893919</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 68 columns</p>\n","</div>"],"text/plain":["   HE_ht  HE_wt  HE_wc     HE_BMI  N_WAT_C       N_INTK         N_EN  \\\n","0  153.4   68.1   81.9  28.939858      3.5  1198.226616  1930.920992   \n","1  171.2   84.0   85.5  28.659708      4.0  2099.617699  3007.329713   \n","2  160.8   52.2   71.0  20.188238      3.0   779.230888  1502.406756   \n","3  168.8   68.8   84.0  24.145909      5.0  1165.590400  1116.380721   \n","4  162.2   80.5   98.4  30.598080     15.0  2336.472416  2465.075672   \n","\n","       N_WATER      N_PROT       N_FAT     ...      HE_HP_2.0  HE_HP_3.0  \\\n","0   761.873294   69.515824   57.722349     ...              0          0   \n","1  1427.204406  109.849807  100.764835     ...              1          0   \n","2   443.763134   57.129583   39.501421     ...              0          1   \n","3   911.584789   36.183575   28.630711     ...              1          0   \n","4  1897.949605   72.131360   68.893919     ...              1          0   \n","\n","   HE_DM_1.0  HE_DM_2.0  HE_DM_3.0  HE_HCHOL_0.0  HE_HCHOL_1.0  GS_use_1.0  \\\n","0          1          0          0             1             0           1   \n","1          1          0          0             1             0           1   \n","2          0          0          1             1             0           1   \n","3          1          0          0             1             0           1   \n","4          1          0          0             1             0           1   \n","\n","   GS_use_2.0  GS_use_3.0  \n","0           0           0  \n","1           0           0  \n","2           0           0  \n","3           0           0  \n","4           0           0  \n","\n","[5 rows x 68 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"1X82VUNYzez3","colab_type":"code","outputId":"cf0bcbe5-3a9c-40a6-ecfc-c3ad25a600be","colab":{}},"cell_type":"code","source":["features.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11323, 68)"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"QWLfQ5sbzez7","colab_type":"code","outputId":"94250feb-5a23-4388-f1c7-f02f64f0b95e","colab":{}},"cell_type":"code","source":["target.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28.4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>36.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31.7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0\n","0  28.4\n","1  50.6\n","2  33.6\n","3  36.5\n","4  31.7"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"49AP2aJ6zez_","colab_type":"code","outputId":"4f344398-d81d-4f05-a1ba-00f6778512d1","executionInfo":{"status":"ok","timestamp":1543613206599,"user_tz":-540,"elapsed":612,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["target.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11323,)"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"eEdLEZsYADnJ","colab_type":"code","colab":{}},"cell_type":"code","source":["target = np.array(target)\n","target = target.reshape((11323))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qUP362npze0D","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8-6m4J6mze0E","colab_type":"text"},"cell_type":"markdown","source":["|**Model**|**Module**|**Explain**|\n","|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n","|**8. [Ensemble Methods](http://scikit-learn.org/stable/modules/ensemble.html#ensemble-methods)**|[sklearn.ensemble](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)||\n","|[Bagging](http://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator)|[ensemble.BaggingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor)|A Bagging regressor.|\n","|[Random Forests](http://scikit-learn.org/stable/modules/ensemble.html#random-forests)|[ensemble.RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)|A random forest regressor.|\n","|[AdaBoost](http://scikit-learn.org/stable/modules/ensemble.html#adaboost)|[ensemble.AdaBoostRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor)|An AdaBoost regressor.|\n","|[Gradient Tree Boosting](http://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)|[ensemble.GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor)|Gradient Boosting for regression.|"]},{"metadata":{"id":"DHCn9qf8ze0F","colab_type":"text"},"cell_type":"markdown","source":["# Ensemble methods\n","http://scikit-learn.org/stable/modules/ensemble.html#ensemble-methods"]},{"metadata":{"id":"h3Ig0eIeze0G","colab_type":"text"},"cell_type":"markdown","source":["앙상블 기법의 목표는 단일 추정기에 대한 일반화 가능성/강직성을 향상시키기 위해 주어진 학습 알고리즘으로 구축된 여러 기본 추정치의 예측을 결합하는 것입니다.\n","\n","앙상블 방법은 일반적으로 두 가지 패밀리가 구분됩니다.(averaging method, boosting method)\n","\n","1. 평균화 방법에서 작동 원리는 여러개 추정량을 독립적으로 작성한 다음 예측치를 평균화하는 것입니다. <br>\n","평균적으로, 결합된 추청치는 분산이 감소되기 때문에 보통 단일 추정기보다 우수합니다.\n","\n","    ex) Bagging methods, Forests of randomized trees, \n","\n","\n","\n","2. 부스팅 방법에서 기본 추정량은 순차적으로 구축되고 결합된 추정량의 편향(bias)을 줄이려고합니다. <br>\n","motivation는 여러 가지 약한 모델을 결합하여 강력한 앙상블을 제작하는 것입니다.\n","\n","    ex) AdaBoost, Gradient Tree Boosting, …"]},{"metadata":{"id":"7n64aTYTze0H","colab_type":"text"},"cell_type":"markdown","source":["## Forests of randomized trees"]},{"metadata":{"id":"clCCdxCxze0I","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","from sklearn.datasets import make_friedman1\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","\n","params = {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2,\n","          'learning_rate': 0.01, 'loss': 'ls'}\n","\n","clf = ensemble.GradientBoostingRegressor(**params)\n","\n","clf.fit(X_train, y_train)\n","\n","mse = mean_squared_error(y_test, clf.predict(X_test))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"48Yde3vvze0K","colab_type":"code","colab":{}},"cell_type":"code","source":["mse"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mF9OSXbUze0M","colab_type":"code","colab":{}},"cell_type":"code","source":["clf.score(X_test, y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CvO0QsN-ze0P","colab_type":"text"},"cell_type":"markdown","source":["## Bagging meta-estimator\n","https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator"]},{"metadata":{"id":"11cNBXGVze0Q","colab_type":"text"},"cell_type":"markdown","source":["앙상블 알고리즘에서 bagging method은 원래의 training set의 random subset에서 black-box estimator의 여러 인스턴스를 구성한 다음<br>\n","개별 예측들을 집계하여 최종 예측을 만듭니다.\n","\n","이러한 방법은 base estimator(e.g., a decision tree)의 분산을 줄이기위한 방법으로, 무작위화를 모델을 구성하는 절차에 도입한 다음 앙상블을 만들어내는 방식으로 사용됩니다.\n","\n","대부분의 경우 bagging method는 기본 알고리즘을 적용할 필요없이 단일 모델과 관련하여 개선할 수 있는 매우 간단한 방법을 구성합니다.\n","\n","이 방법이 overfitting을 줄이는 방법을 제공하기 때문에 bagging method은 강하고 복잡한 모델(e.g., fully developed decision trees)에서 가장 잘 작동합니다.<br>\n","(일반적으로 약한 모델(e.g., shallow(얕은) decision trees)에서 가장 잘 작동하는 boosting method과 대조적입니다.)"]},{"metadata":{"id":"fFTEE8ojze0R","colab_type":"text"},"cell_type":"markdown","source":["Bagging method은 여러 가지 flavour이 있지만 training set의 random subset을 추출하는 방식에 따라 서로 다릅니다.\n","\n","- dataset의 random subset이 sample의 random subset로 추출되면 이 알고리즘을 **pasting(붙여넣기)**라고 합니다 [B1999](https://scikit-learn.org/stable/modules/ensemble.html#b1999).\n","- sample이 복원추출될 때 이 방법을 **Bagging** [B1996](https://scikit-learn.org/stable/modules/ensemble.html#b1996)이라고 합니다.\n","- dataset의 random subset이 feature의 random subset으로 추출되면 이 방법을 **Random Subspaces** [H1998](https://scikit-learn.org/stable/modules/ensemble.html#h1998)이라고 합니다.\n","- 마지막으로, sample과 feature 둘 다의 subset으로 만들어진 Base Estimator는 **Random Patches**로 알려져 있습니다 [LG2012](https://scikit-learn.org/stable/modules/ensemble.html#lg2012)"]},{"metadata":{"id":"-c64di4Dze0T","colab_type":"text"},"cell_type":"markdown","source":["**parameter**"]},{"metadata":{"id":"8ctkrNy9ze0T","colab_type":"text"},"cell_type":"markdown","source":["scikit-learn에서 bagging method은 통합 BaggingClassifier  meta-estimator로 제공됩니다(resp. BaggingRegressor)\n","\n","사용자 지정 base estimator 입력과 random subsets를 추출하는 전략을 지정하는 매개 변수를 사용합니다. \n","\n","특히 `max_samples` 및 `max_features`는 subset의 크기(samples and features 측면에서)를 제어하고<br>\n","`bootstrap` 및 `bootstrap_features`는 sample 및 feature을 복원 및 비복원추출 여부를 제어합니다.\n","\n","사용 가능한 sample의 subset를 사용할 때 일반화 정확도는 `oob_score=True`를 설정하여 out-of-bag sample로 추정할 수 있습니다. \n","\n","예를 들어, 아래 snippet은 각각 sample의 50%와 feature의 50%의 random subset으로 구축된 KnearborsClassifier base Estimators의 bagging ensemble을 인스턴스화하는 방법을 보여줍니다."]},{"metadata":{"id":"fFmdMXzWze0U","colab_type":"text"},"cell_type":"markdown","source":["```python\n",">>> from sklearn.ensemble import BaggingClassifier\n",">>> from sklearn.neighbors import KNeighborsClassifier\n",">>> bagging = BaggingClassifier(KNeighborsClassifier(),\n","...                             max_samples=0.5, max_features=0.5)\n","```"]},{"metadata":{"id":"bc6ZACqhze0V","colab_type":"text"},"cell_type":"markdown","source":["### sklearn.ensemble.BaggingRegressor\n","https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn-ensemble-baggingregressor"]},{"metadata":{"id":"SfmAEY9xze0W","colab_type":"text"},"cell_type":"markdown","source":["Bagging regressor는 기본 regressor를 원래 데이터 세트의 random subset에 각각 적합시킨 다음 개별 예측(투표 또는 평균)을 집계하여 최종 예측을 구성하는 ensemble meta-estimator입니다. "]},{"metadata":{"id":"NLsMa8yaze0W","colab_type":"text"},"cell_type":"markdown","source":["```python\n","class sklearn.ensemble.BaggingRegressor(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)\n","```"]},{"metadata":{"id":"mIy9HtvCze0Y","colab_type":"text"},"cell_type":"markdown","source":["`base_estimator` : object or None, optional *(default=None)*<br>\n","데이터셋의 random subsets에 적합시키기 위한 base estimator *(default=None : decision tree)*\n","\n","`n_estimators` : int, optional *(default=10)*<br>\n","The number of base estimators in the ensemble.\n","\n","`max_samples` : int or float, optional *(default=1.0)*<br>\n","각 base estimator을 훈련하기 위해 X에서 추출할 sample 수.\n","- If int, then draw `max_samples` samples.<br>\n","- If float, then draw `max_samples` * X.shape[0] samples.\n","\n","`max_features` : int or float, optional *(default=1.0)*<br>\n","각 base estimator을 훈련하기 위해 X로 부터 추출할 feature 수.\n","\n","- If int, then draw `max_features` features.\n","- If float, then draw `max_features` * X.shape[1] features.\n","\n","`bootstrap` : boolean, optional *(default=True)*<br>\n","sample의 복원추출 여부\n","\n","`bootstrap_features` : boolean, optional *(default=False)*<br>\n","feature의 복원추출 여부"]},{"metadata":{"id":"h1S_qW6uze0Y","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JiMRuO2bze0b","colab_type":"code","colab":{}},"cell_type":"code","source":["n_estimators = [10, 100]  \n","max_samples = [0.5, 1.0]\n","max_features = [0.5, 1.0]\n","bootstrap = [True, False]\n","bootstrap_features = [True, False]\n","param_grid = dict(n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, bootstrap=bootstrap, bootstrap_features=bootstrap_features)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IUp1xSaHze0e","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import KFold\n","kfold = KFold(n_splits=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hXL9Mghcze0i","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.ensemble import BaggingRegressor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VKTynFivze0l","colab_type":"code","colab":{}},"cell_type":"code","source":["grid = GridSearchCV(BaggingRegressor(), param_grid=param_grid, return_train_score=True, cv = kfold)"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"lgEkvGxHze0o","colab_type":"code","colab":{}},"cell_type":"code","source":["grid_result = grid.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pRY8eyXJze0r","colab_type":"code","outputId":"2af27c76-2414-48e4-c6b4-f808873b7cb2","colab":{}},"cell_type":"code","source":["grid.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6522857179650828"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"Q2JKwIbYze0u","colab_type":"code","outputId":"80517a99-54c9-4eb3-b38a-bbf951d1b5a9","colab":{}},"cell_type":"code","source":["grid.best_params_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bootstrap': False,\n"," 'bootstrap_features': False,\n"," 'max_features': 1.0,\n"," 'max_samples': 0.5,\n"," 'n_estimators': 100}"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"FFkmpJyaze0x","colab_type":"code","outputId":"2be596ef-21d5-44d1-9980-16bd6b899193","colab":{}},"cell_type":"code","source":["grid.best_estimator_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BaggingRegressor(base_estimator=None, bootstrap=False,\n","         bootstrap_features=False, max_features=1.0, max_samples=0.5,\n","         n_estimators=100, n_jobs=None, oob_score=False, random_state=None,\n","         verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"eue6P-K0ze0z","colab_type":"text"},"cell_type":"markdown","source":["## AdaBoost\n","https://scikit-learn.org/stable/modules/ensemble.html#adaboost"]},{"metadata":{"id":"n06EqZkVze00","colab_type":"text"},"cell_type":"markdown","source":["AdaBoost의 핵심 원리는 반복적으로 train set에서 데이터 sample를 추출하여 일련의 약한 학습기(`base_estimator`)에 적합시키는 것입니다.\n","그런 다음 이들 모두의 예측을 다수결 투표(또는 합계)를 통해 결합되어 최종 예측을 산출합니다. \n","\n","이른바 boosting 반복에서의 데이터 수정은 가중치 $w_1, w_2, ..., w_N$를 각각의 training sample에 적용하는 것으로 구성됩니다.<br>\n","처음에는 그 가중치가 모두 $w_i = 1/N$로 설정되어 있으므로 첫 번째 단계에서는 약한 학습기에 원본 데이터를 간단하게 훈련시킵니다.\n","\n","연속되는 각 반복에 대해 sample의 가중치가 개별적으로 수정되고 학습 알고리즘(`base_estimator`)이 재가중된 데이터에 다시 적용됩니다. \n","\n","특정 단계에서, 이전 단계로 부터 유도된 boost 모델에 의해 부정확하게 예측된 training example는 가중치가 증가하는 \n","반면 올바르게 예측된 training example는 가중치가 감소합니다. \n","\n","반복 작업이 진행됨에 따라 예측하기 어려운 example는 가중치가 계속 증가하는 영향을 받습니다. 따라서 후속의 약한 학습기는[[HTF](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)] 시퀀스에서 이전 학습기가 놓친 example에 집중합니다."]},{"metadata":{"id":"z9HG1mO2ze01","colab_type":"text"},"cell_type":"markdown","source":["**Usage(사용법)**"]},{"metadata":{"id":"Uqz6cdC4ze01","colab_type":"text"},"cell_type":"markdown","source":["다음 예는 약한 학습기 100개와 함께 AdaBoost classifier를 적용하는 방법을 보여줍니다.\n","\n","```python\n",">>> from sklearn.model_selection import cross_val_score\n",">>> from sklearn.datasets import load_iris\n",">>> from sklearn.ensemble import AdaBoostClassifier\n","\n",">>> iris = load_iris()\n",">>> clf = AdaBoostClassifier(n_estimators=100)\n",">>> scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",">>> scores.mean()                             \n","0.9...\n","```"]},{"metadata":{"id":"spz4w_IUze02","colab_type":"text"},"cell_type":"markdown","source":["약한 학습기의 수는 매개 변수 `n_estimator`에 의해 제어됩니다. <br>\n","`learning_rate` 매개 변수는 최종 조합에서 약한 학습기의 기여를 제어합니다. \n","\n","기본적으로 약한 학습기는 의사 결정의 stumps입니다.<br>\n","`base_estimator` 매개 변수를 통해 여러 약한 학습기를 지정할 수 있습니다.<br>\n","좋은 결과를 얻기 위해 튜닝하는 주요 매개변수는 `n_estimators` 및 base estimator의 복잡성(e.g., 깊이`max_depth` 또는 분할을 고려하는 데 필요한 최소 샘플 수`min_samples_split`)입니다."]},{"metadata":{"id":"k005dNWqze02","colab_type":"text"},"cell_type":"markdown","source":["### sklearn.ensemble.AdaBoostRegressor\n","https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn-ensemble-adaboostregressor"]},{"metadata":{"id":"rJDzo9KFze03","colab_type":"text"},"cell_type":"markdown","source":["AdaBoost regressor는 원본 데이터 세트에 적합한 다음 동일한 데이터셋에 추가적으로 regressor의 복사본을 적합시키지만 인스턴스의 가중치가 현재 예측의 error에 따라 조정되는 meta-estimator입니다. 따라서 후속 regressor들은 예측이 어려운 것에 더 초점을 맞춥니다."]},{"metadata":{"id":"xtNe1nt_ze04","colab_type":"text"},"cell_type":"markdown","source":["```python\n","class sklearn.ensemble.AdaBoostRegressor(base_estimator=None, n_estimators=50, learning_rate=1.0, loss='linear', random_state=None)\n","```"]},{"metadata":{"id":"yPgsHIZEze04","colab_type":"text"},"cell_type":"markdown","source":["**parameter**"]},{"metadata":{"id":"RuLnmk7-ze05","colab_type":"text"},"cell_type":"markdown","source":["`base_estimator` : object, optional *(default=None)*<br>\n","boosted 앙상블이 생성되는 기본 추정기입니다. sample 가중치 지원이 필요합니다.<br>\n","If None, then the base estimator is DecisionTreeRegressor(max_depth=3)\n","\n","`n_estimators` : integer, optional *(default=50)*<br>\n","boosting이 종료되는 최대 estimator의 수. 완벽한 적합의 경우, 학습 절차가 일찍 중단됩니다.\n","\n","`learning_rate` : float, optional *(default=1.)*<br>\n","Learning rate은 `learning_rate`로 인한 각 regressor의 기여를 줄입니다. `learning_rate`와 `n_estimators` 사이에는 trade-off가 있습니다.\n","\n","`loss` : {'linear', 'square', 'exponential'}, optional *(default='linear')*<br>\n","각 boosting 반복 후에 가중치를 업데이트할 때 사용할 손실 함수입니다."]},{"metadata":{"id":"WSE9MG_Cze07","colab_type":"code","colab":{}},"cell_type":"code","source":["ada = AdaBoostRegressor()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kLBaXLAmze0-","colab_type":"code","outputId":"8c1876cc-d35a-4753-ff0c-a5fd561251d0","colab":{}},"cell_type":"code","source":["ada.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n","         n_estimators=50, random_state=None)"]},"metadata":{"tags":[]},"execution_count":39}]},{"metadata":{"id":"5k2aIgY0ze1B","colab_type":"code","outputId":"552c3e49-a4c8-44c5-a3b3-e1e4d630f3e7","colab":{}},"cell_type":"code","source":["ada.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.61168095425129"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"nnVX-yJuze1D","colab_type":"code","colab":{}},"cell_type":"code","source":["n_estimators = [10, 50, 100]  \n","learning_rate = [0.001, 0.01, 0.1]\n","loss = ['linear', 'square', 'exponential']\n","param_grid = dict(n_estimators=n_estimators, learning_rate=learning_rate, loss=loss)\n","kfold = KFold(n_splits=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"snBa1nS5ze1F","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.ensemble import AdaBoostRegressor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kCxd2g5tze1I","colab_type":"code","colab":{}},"cell_type":"code","source":["grid = GridSearchCV(AdaBoostRegressor(), param_grid=param_grid, return_train_score=True, cv = kfold)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6eib6ZRqze1K","colab_type":"code","outputId":"999f572e-bc5f-4505-976f-72ee696c9426","colab":{}},"cell_type":"code","source":["AdaBoostRegressor().get_params().keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['base_estimator', 'learning_rate', 'loss', 'n_estimators', 'random_state'])"]},"metadata":{"tags":[]},"execution_count":31}]},{"metadata":{"scrolled":true,"id":"G7UenoZrze1O","colab_type":"code","colab":{}},"cell_type":"code","source":["grid_result = grid.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yf7KMPpB_hoW","colab_type":"code","colab":{}},"cell_type":"code","source":["grid.score(X_test, y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sTd8Hd3shJih","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LqrXor1OhPrJ","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f42KQcZdhmin","colab_type":"code","outputId":"bf833815-2f36-491e-811d-212d37d7c1f1","executionInfo":{"status":"ok","timestamp":1543613962729,"user_tz":-540,"elapsed":885,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"cell_type":"code","source":["from sklearn.linear_model import RidgeCV\n","ridgecv = RidgeCV(alphas=[10**i for i in [2, 1, 0, -1, -2]], cv=3)\n","ridgecv.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RidgeCV(alphas=[100, 10, 1, 0.1, 0.01], cv=3, fit_intercept=True,\n","    gcv_mode=None, normalize=False, scoring=None, store_cv_values=False)"]},"metadata":{"tags":[]},"execution_count":36}]},{"metadata":{"id":"42PXsXc3k0dM","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.linear_model import Ridge"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EgqaHHz4jf6i","colab_type":"code","outputId":"6ebcaaee-d41d-4ce2-f221-abe24f9bf21c","executionInfo":{"status":"ok","timestamp":1543613904206,"user_tz":-540,"elapsed":667,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["ridgecv.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6393988535294128"]},"metadata":{"tags":[]},"execution_count":31}]},{"metadata":{"id":"PHZV2BXTjn4u","colab_type":"code","outputId":"eef0e474-e5d1-420c-f343-96029df3ee41","executionInfo":{"status":"ok","timestamp":1543613917378,"user_tz":-540,"elapsed":674,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["ridgecv.store_cv_values"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":32}]},{"metadata":{"id":"K4Pt2gFWhsQC","colab_type":"code","outputId":"a76d3a64-2af3-43b6-f007-f7b9e99b6013","executionInfo":{"status":"ok","timestamp":1543614086113,"user_tz":-540,"elapsed":74925,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","lasso = Lasso(alpha=0.1, max_iter=30000)\n","lasso.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=30000,\n","   normalize=False, positive=False, precompute=False, random_state=None,\n","   selection='cyclic', tol=0.0001, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":37}]},{"metadata":{"id":"wzf8U1CQknrj","colab_type":"code","outputId":"1f92fdec-1ac2-4f8d-91aa-f790eb3ba779","executionInfo":{"status":"ok","timestamp":1543614155341,"user_tz":-540,"elapsed":680,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["lasso.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6323860284020153"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"NBgWiUulkP39","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a pipeline\n","pipe = Pipeline([('regressor', Ridge())])\n","\n","\n","search_space = [{'regressor': [Ridge()],\n","                 'regressor__alpha':[10**i for i in [2, 1, 0, -1, -2]]},\n","                {'regressor': [Lasso()],\n","                 'regressor__alpha':[10**i for i in [2, 1, 0, -1, -2]],\n","                 'regressor__max_iter': [30000]}]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0xT2xKrNkQ6K","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import KFold\n","kfold = KFold(n_splits=5)\n","regCV = GridSearchCV(pipe, search_space, cv=kfold)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7fj3JQnAk_IU","colab_type":"code","outputId":"7a61cb93-ccef-4c53-d0ec-66ccf7127418","executionInfo":{"status":"ok","timestamp":1543615347152,"user_tz":-540,"elapsed":918125,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"cell_type":"code","source":["regCV.fit(X_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n","       error_score='raise',\n","       estimator=Pipeline(memory=None,\n","     steps=[('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n","   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n","       fit_params=None, iid=True, n_jobs=1,\n","       param_grid=[{'regressor': [Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n","   normalize=False, random_state=None, solver='auto', tol=0.001)], 'regressor__alpha': [100, 10, 1, 0.1, 0.01]}, {'regressor': [Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=300000,\n","   normalize=False, positive=False, precompute=False, random_state=None,\n","   selection='cyclic', tol=0.0001, warm_start=False)], 'regressor__alpha': [100, 10, 1, 0.1, 0.01], 'regressor__max_iter': [300000]}],\n","       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n","       scoring=None, verbose=0)"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"cfD269J5pVZq","colab_type":"code","outputId":"c7a68872-ef9c-4c30-a486-3701b432fc1e","executionInfo":{"status":"ok","timestamp":1543615392022,"user_tz":-540,"elapsed":744,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["regCV.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6396655296797711"]},"metadata":{"tags":[]},"execution_count":47}]},{"metadata":{"id":"jEFVW59epgZw","colab_type":"code","outputId":"a3c4acd9-9c98-43a5-8280-1a7814d4d911","executionInfo":{"status":"ok","timestamp":1543615424144,"user_tz":-540,"elapsed":786,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"cell_type":"code","source":["regCV.best_estimator_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('regressor', Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=300000,\n","   normalize=False, positive=False, precompute=False, random_state=None,\n","   selection='cyclic', tol=0.0001, warm_start=False))])"]},"metadata":{"tags":[]},"execution_count":48}]},{"metadata":{"id":"ery14ZzEmTOK","colab_type":"text"},"cell_type":"markdown","source":["위에서 수행한 ridgecv와 lasso를 Ensemble 모델의 base_estimator 매개변수의 값으로 넣어 gridsearch를 수행한다."]},{"metadata":{"id":"O4NTuhcZhSgO","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a pipeline\n","pipe = Pipeline([('regressor', AdaBoostRegressor())])\n","\n","ensemble_search = [{'regressor': [AdaBoostRegressor()],\n","                 'regressor__base_estimator': [ridgecv, lasso]},\n","               {'regressor': [BaggingRegressor()],\n","                 'regressor__base_estimator': [ridgecv, lasso]}]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wVqYBkcshgBw","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import KFold\n","kfold = KFold(n_splits=5)\n","ensembleCV = GridSearchCV(pipe, ensemble_search, cv=kfold)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6ob6433ChgjR","colab_type":"code","colab":{}},"cell_type":"code","source":["ensembleCV.fit(X_train,y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OsaCpudljG2c","colab_type":"code","outputId":"c3493496-7e28-4723-d29c-43ca448e1d0d","executionInfo":{"status":"ok","timestamp":1543613792999,"user_tz":-540,"elapsed":676,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["ensembleCV.score(X_test,y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6369536050736472"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"ym7AKw9MjUr0","colab_type":"code","outputId":"f2988002-c2ca-4ac1-c800-07e90062a309","executionInfo":{"status":"ok","timestamp":1543613800684,"user_tz":-540,"elapsed":668,"user":{"displayName":"K J","photoUrl":"https://lh4.googleusercontent.com/-B2txY1D14ok/AAAAAAAAAAI/AAAAAAAAAEw/4KV8cEiIlaU/s64/photo.jpg","userId":"03106099213865703675"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"cell_type":"code","source":["regCV.best_estimator_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('regressor', BaggingRegressor(base_estimator=RidgeCV(alphas=[0.1, 1.0, 10.0], cv=3, fit_intercept=True, gcv_mode=None,\n","    normalize=False, scoring=None, store_cv_values=False),\n","         bootstrap=True, bootstrap_features=False, max_features=1.0,\n","         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n","         random_state=None, verbose=0, warm_start=False))])"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"7VkTGdsTppNF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a pipeline\n","pipe = Pipeline([('regressor', AdaBoostRegressor(regCV.best_estimator_))])\n","\n","ensemble_search2 = [{'regressor': [AdaBoostRegressor(regCV.best_estimator_)]},\n","               {'regressor': [BaggingRegressor(regCV.best_estimator_)]}]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"suydUYi0ptmd","colab_type":"code","colab":{}},"cell_type":"code","source":["ensembleCV2 = GridSearchCV(pipe, ensemble_search2, cv=kfold)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"89Nk6Z7CqB16","colab_type":"code","colab":{}},"cell_type":"code","source":["ensembleCV2.fit(X_train,y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FkO-JpVXsa9C","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a pipeline\n","pipe = Pipeline([('regressor', AdaBoostRegressor())])\n","\n","ensemble_search3 = [{'regressor': [AdaBoostRegressor(regCV.best_estimator_)],\n","                 'regressor__n_estimators': [5, 10, 30],\n","                 'regressor__learning_rate': [0.1, 0.01, 0.001],\n","                'regressor_loss': ['linear', 'square', 'exponential']},\n","               {'regressor': [BaggingRegressor(regCV.best_estimator_)],\n","                 'regressor__n_estimators': [5, 10, 30],\n","                 'regressor__max_features': [0.1, 0.5, 1.0],\n","                 'regressor__max_samples': [0.1, 0.5, 1]}]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iCBS4SgTsfiO","colab_type":"code","colab":{}},"cell_type":"code","source":["ensembleCV3 = GridSearchCV(pipe, ensemble_search3, cv=kfold)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pBpSjLXMshTJ","colab_type":"code","colab":{}},"cell_type":"code","source":["ensembleCV3.fit(X_train,y_train)"],"execution_count":0,"outputs":[]}]}